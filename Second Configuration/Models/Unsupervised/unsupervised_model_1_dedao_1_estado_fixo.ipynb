{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"eQ0YSYN2GTpC"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import librosa\n","import librosa.display\n","import IPython.display as ipd\n","import math\n","import plotly.graph_objects as go\n","from plotly.subplots import make_subplots\n","import pandas as pd\n","import plotly.express as px\n","from google.colab import drive\n","from scipy import signal\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn.cluster import KMeans\n","from scipy.signal import windows\n","from scipy.signal import medfilt, savgol_filter\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KaplpWRvNAq3"},"outputs":[],"source":["drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"al6cgm1rIkHU"},"source":["## Arquivos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WG1i38E1Jb8U"},"outputs":[],"source":["arquivos_emg = [\"emg__modulo_aberto_1.csv\",\"emg__modulo_aberto_2.csv\",\"emg__modulo_aberto_3.csv\",\n","                \"emg__modulo_aberto_4.csv\",\"emg__modulo_aberto_5.csv\",\n","                \"emg__modulo_fecha_dedao_resto_aberto_1.csv\",\"emg__modulo_fecha_dedao_resto_aberto_2.csv\",\n","                \"emg__modulo_fecha_dedao_resto_aberto_3.csv\",\n","                \"emg__modulo_fecha_dedao_resto_aberto_4.csv\",\"emg__modulo_fecha_dedao_resto_aberto_5.csv\"]"]},{"cell_type":"code","source":["#arquivos_emg = [\"emg__modulo_fecha_dedao_resto_aberto_1.csv\"]"],"metadata":{"id":"cNKnbn9vkN_0"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8M2jKJNHeiBe"},"outputs":[],"source":["arquivos_abre_fecha_emg = arquivos_emg[:]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r3WX4qwTMP86"},"outputs":[],"source":["FRAME_SIZE = 512*2\n","HOP_LENGTH = int(0.25*FRAME_SIZE)\n","hann_wnd = windows.hann(FRAME_SIZE,sym=False)\n","## o tanto que salta para a direita de um frame para o outro, frames serão sobrepostos\n","## diferentes frames terão amostras iguais"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sRLq64EMMeLN"},"outputs":[],"source":["path = \"drive/My Drive/TCC - Vinícius Franklin - Desenvolvimento de Prótese Ativa Controlada por Sinais EMG Utilizando Classificação com Machine Learning/Testes Dados - EMG/conf_1_dedao/\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bdg0cNlOM2pF"},"outputs":[],"source":["dfs_emg_module  = {}\n","for arquivo in arquivos_emg:\n","\n","\n","  df = pd.read_csv(path + arquivo)\n","  # Garante que os dados estão no formato numérico\n","  df[\"tempo_arduino_micro_s\"] = pd.to_numeric(df[\"tempo_arduino_micro_s\"], errors=\"coerce\")\n","  df[\"valor_ADC\"] = pd.to_numeric(df[\"valor_ADC\"], errors=\"coerce\")\n","\n","\n","  df[\"tempo_arduino_s\"] = df[\"tempo_arduino_micro_s\"]/10**6\n","\n","  periodo = float(df.loc[106,\"tempo_arduino_s\"] - df.loc[105,\"tempo_arduino_s\"])\n","  sr = 1/periodo\n","\n","  tempo = df[\"tempo_arduino_s\"].values\n","  fs_eff = 1 / np.mean(np.diff(tempo))\n","  sr = fs_eff\n","\n","  dfs_emg_module[arquivo] = {\"df\":df,\"periodo\":periodo,\"sr\":sr}\n","  dfs_emg_module[arquivo]['features'] = {}\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fZZFjpbaTnlM"},"outputs":[],"source":["print(f\"Sample Rate: {sr} hz\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CeQQrunVTO5j"},"outputs":[],"source":["frame_size_time = FRAME_SIZE*1/sr\n","print(f\"Frame Size no tempo: {frame_size_time} s\")\n","hop_lenght_time = HOP_LENGTH*1/sr\n","print(f\"HOP LENGHT no tempo: {hop_lenght_time} s\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YMNVROsY7U3A"},"outputs":[],"source":["def plot_magnitude_spectrum(signal, sr, title, f_ratio=1,norm=0):\n","    # FFT\n","    X = np.fft.fft(signal)\n","    X_mag = np.abs(X)\n","\n","\n","    # Frequência\n","    # Normalizando pelo Valor Total\n","    f = np.linspace(0, sr, len(X_mag))\n","    f_bins = int(len(X_mag) * f_ratio)\n","\n","    X_mag = np.abs(X_mag[:f_bins//2])**2\n","\n","    if norm != 0:\n","      X_mag = X_mag/sum(X_mag)\n","\n","    # Plotly\n","    fig = go.Figure()\n","    fig.add_trace(go.Scatter(\n","        x=f[:f_bins//2],\n","        y=X_mag,\n","        mode='lines',\n","        name='Magnitude Normalizada'\n","    ))\n","\n","    fig.update_layout(\n","        title=title,\n","        xaxis_title='Frequency (Hz)',\n","        yaxis_title='Magnitude Normalizada',\n","        width=900,\n","        height=400\n","    )\n","\n","    fig.show()\n","    # retornar so a parte positiva, ja que é simetrico\n","    return X_mag[:f_bins//2],f,f_bins\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B1BvqOsqV-lO"},"outputs":[],"source":["def simple_moving_average(data, window_size=6):\n","    weights = np.ones(window_size) / window_size\n","    sma = np.convolve(data, weights, mode='same')\n","    return sma\n","\n","def median_clean(signal, kernel_size=7):\n","  # kernel_size deve ser ímpar\n","  k = kernel_size if kernel_size % 2 == 1 else kernel_size + 1\n","  return medfilt(signal, kernel_size=k)\n","\n","\n","def majority_vote(labels, window=5):\n","    half = window // 2\n","    padded = np.pad(labels, (half, half), mode='edge')\n","    out = np.zeros_like(labels)\n","    for i in range(len(labels)):\n","        win = padded[i:i+window]\n","        out[i] = np.bincount(win).argmax()\n","    return out\n","\n","def run_length_smooth(labels, min_run_length=5):\n","    # labels: 1D array of 0/1\n","    out = labels.copy()\n","    n = len(labels)\n","    i = 0\n","    while i < n:\n","        j = i\n","        while j < n and labels[j] == labels[i]:\n","            j += 1\n","        run_len = j - i\n","        if run_len < min_run_length:\n","            out[i:j] = 1 - labels[i]  # flip short run\n","        i = j\n","    return out\n","\n"]},{"cell_type":"markdown","metadata":{"id":"MwuLLxLr61P0"},"source":["## Original"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4xgOoDrQ63y0"},"outputs":[],"source":["\n","for arquivo in arquivos_emg[:]:\n","    df = dfs_emg_module[arquivo][\"df\"]\n","\n","    # Vetores já existentes\n","    t = df[\"tempo_arduino_s\"].values\n","    y = df[\"valor_ADC\"].values\n","\n","    # Remove a componente média (DC) apenas no vetor\n","    y_sem_dc = y - y.mean()\n","\n","    # Cria o gráfico interativo usando arrays diretamente\n","    fig = px.line(\n","        x=t,\n","        y=y_sem_dc,\n","        title=f\"Sinal EMG (sem componente média) — {arquivo}\",\n","        labels={\"x\": \"Tempo (s)\", \"y\": \"Amplitude (uADC)\"}\n","    )\n","    fig.update_layout(template=\"plotly_white\")\n","    fig.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XqgZK_Hf8FR0"},"outputs":[],"source":["for data in arquivos_emg[:]:\n","  valor = dfs_emg_module[data][\"df\"].valor_ADC.values\n","  valor = valor - valor.mean()\n","  plot_magnitude_spectrum(valor ,dfs_emg_module[data][\"sr\"],data,norm=1)"]},{"cell_type":"markdown","metadata":{"id":"895DaItN-M4W"},"source":["## Filtro"]},{"cell_type":"markdown","metadata":{"id":"IN6_opMu-Pxm"},"source":["Resumo da decisão sobre filtragem EMG no pipeline\n","\n","Para o processamento dos sinais EMG, inicialmente utilizei um filtro Butterworth passa-faixa (20–500 Hz, ordem 8) com sosfiltfilt, garantindo fase zero e evitando distorções temporais. Porém, esse tipo de filtragem não pode ser embarcado no microcontrolador, já que exige filtrar o sinal para frente e para trás.\n","\n","Por isso, a solução adotada para uso real é aplicar o mesmo filtro Butterworth, mas agora de forma causal com sosfilt, que é compatível com implementação embarcada (IIR em cascata de SOS). O filtro causal possui atraso de grupo e distorção de fase, mas, como o modelo de machine learning é treinado com esse mesmo filtro, ele aprende esses padrões e não há perda prática de desempenho.\n","\n","Para validar a robustez do pipeline, posso comparar os clusters obtidos com o dataset filtrado por sosfilt (causal) e com sosfiltfilt (fase zero). Se os agrupamentos forem semelhantes, isso confirma que a distorção de fase do filtro causal não compromete a separação das classes.\n","\n","Assim, para uso embarcado e treinamento consistente, o processamento adotado é:\n","\n","Filtro IIR Butterworth passa-faixa (20–500 Hz)\n","\n","Implementação causal utilizando signal.sosfilt\n","\n","Frames de 1024 samples com hop de 25%\n","\n","Essa abordagem mantém compatibilidade com o hardware e garante uniformidade entre treino e execução em tempo real."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eEkiAGek6UZ0"},"outputs":[],"source":["from scipy import signal\n","\n","for data in arquivos_emg[:]:\n","  valor = dfs_emg_module[data][\"df\"].valor_ADC.values\n","  valor = valor - valor.mean()\n","  # Butterworth bandstop como Second-Order Sections\n","  sos = signal.butter(N=8, Wn=[20, 500], btype='bandpass', fs=dfs_emg_module[data][\"sr\"], output='sos')\n","\n","\n","\n","  # Aplica o filtro\n","  filtered_nc = signal.sosfiltfilt(sos = sos, x = valor)\n","  filtered_c = signal.sosfilt(sos = sos, x = valor)\n","  # Média Móvel\n","  #filtered = simple_moving_average(data=filtered)\n","\n","  #sos = signal.butter(N=8, Wn=[70, 90], btype='bandstop', fs=sr, output='sos')\n","  #filtered_nc = signal.sosfiltfilt(sos = sos, x = filtered_nc)\n","  #filtered_c = signal.sosfilt(sos = sos, x = filtered_c)\n","  ## Filtro Mediano\n","  ##filtered = median_clean(filtered)\n","#\n","  #sos = signal.butter(N=1, Wn=[225, 245], btype='bandstop', fs=sr, output='sos')\n","  #filtered_nc = signal.sosfiltfilt(sos = sos, x = filtered_nc)\n","  #filtered_c = signal.sosfilt(sos = sos, x = filtered_c)\n","#\n","  #sos = signal.butter(N=8, Wn=[140, 160], btype='bandstop', fs=sr, output='sos')\n","  #filtered_nc = signal.sosfiltfilt(sos = sos, x = filtered_nc)\n","  #filtered_c = signal.sosfilt(sos = sos, x = filtered_c)\n","#\n","#\n","  #sos = signal.butter(N=1, Wn=[305, 320], btype='bandstop', fs=sr, output='sos')\n","  #filtered_nc = signal.sosfiltfilt(sos = sos, x = filtered_nc)\n","  #filtered_c = signal.sosfilt(sos = sos, x = filtered_c)\n","\n","  dfs_emg_module[data][\"filtered\"] = filtered_c\n","  dfs_emg_module[data][\"filtered_Nao_Causal\"] = filtered_nc\n","  plot_magnitude_spectrum(dfs_emg_module[data][\"filtered\"] ,dfs_emg_module[data][\"sr\"],data,norm=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1rZPWBkYwh4G"},"outputs":[],"source":["for data in arquivos_abre_fecha_emg[:]:\n","\n","    sinal = dfs_emg_module[data][\"filtered_Nao_Causal\"]\n","\n","    fig = go.Figure()\n","\n","    # Plot do sinal EMG\n","    fig.add_trace(go.Scatter(\n","        x=np.arange(len(sinal))/sr,\n","        y=sinal,\n","        mode='lines',\n","        name='EMG Não Causal',\n","        line=dict(color='blue', width=1)\n","    ))\n","\n","    fig.update_layout(\n","        title=f\"{data} — Sinal EMG Depois do Filtro Não Causal\",\n","        xaxis_title=\"Tempo (s)\",\n","        yaxis_title=\"Amplitude (uADC)\",\n","        height=500\n","    )\n","\n","    # Mostra o gráfico no navegador\n","    fig.show()\n","\n","\n","    sinal = dfs_emg_module[data][\"filtered\"]\n","\n","    fig = go.Figure()\n","\n","    # Plot do sinal EMG\n","    fig.add_trace(go.Scatter(\n","        x=np.arange(len(sinal))/sr,\n","        y=sinal,\n","        mode='lines',\n","        name='EMG Causal',\n","        line=dict(color='blue', width=1)\n","    ))\n","\n","    fig.update_layout(\n","        title=f\"{data} — Sinal EMG Depois do Filtro Causal\",\n","        xaxis_title=\"Tempo (s)\",\n","        yaxis_title=\"Amplitude (uADC)\",\n","        height=500\n","    )\n","\n","\n","\n","\n","    # Mostra o gráfico no navegador\n","    fig.show()"]},{"cell_type":"markdown","metadata":{"id":"cckhcAeTPaJF"},"source":["## Amplitude Envelope"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CPto_W_yNPoo"},"outputs":[],"source":["## calculate the amplitude envelope, but the module, so because its centered in 0\n","def amplitude_envelope(signal, frame_size, hop_length):\n","    amplitude_envelope = []\n","\n","    # calculate the AE for each frame\n","\n","    for i in range(0, len(signal) - frame_size + 1, hop_length):\n","        wnd = signal[i:i+frame_size]\n","        wnd = wnd*hann_wnd\n","        max_value = max(wnd)\n","        min_value = min(wnd)\n","        current_frame_amplitude_envelope = max_value if max_value > np.abs(min_value) else min_value\n","        amplitude_envelope.append(current_frame_amplitude_envelope)\n","\n","    return np.array(amplitude_envelope)\n","\n","\n","def fancy_amplitude_envelope(signal, frame_size, hop_length):\n","    return np.array([max(signal[i:i+frame_size]) for i in range(0,signal.size, hop_length)])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"71cP6d2Ui9Kx"},"outputs":[],"source":["for arquivo in arquivos_emg:\n","  filt_values = dfs_emg_module[arquivo][\"filtered\"]\n","  amp_en = amplitude_envelope(filt_values,FRAME_SIZE,HOP_LENGTH)\n","  dfs_emg_module[arquivo]['features']['amp_en']  = amp_en\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UY9LONBzkpQs"},"outputs":[],"source":["amplitude_envelope(df[\"valor_ADC\"].values,FRAME_SIZE,HOP_LENGTH)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6lRcVVSYkrZU"},"outputs":[],"source":["for arquivo in arquivos_emg:\n","  ae = dfs_emg_module[arquivo]['features'][\"amp_en\"]\n","  adc_valus = dfs_emg_module[arquivo][\"filtered\"]\n","  sr = dfs_emg_module[arquivo][\"sr\"]\n","  t = np.arange(len(ae)) * HOP_LENGTH / sr\n","  # Cria subplots\n","  fig = go.Figure()\n","\n","  # ECG filtrado\n","  fig.add_trace(go.Scatter(x=np.arange(len(adc_valus))/sr, y=adc_valus,\n","                          mode='lines', name='EMG', line=dict(color='blue'), opacity=0.5))\n","\n","  # Envelope sobreposto\n","  fig.add_trace(go.Scatter(x=t, y=ae,\n","                          mode='lines', name='AE', line=dict(color='red', width=2)))\n","\n","  fig.update_layout(title=arquivo)\n","\n","  fig.show()"]},{"cell_type":"markdown","metadata":{"id":"Sp1qf7AWPcuT"},"source":["## RMS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g5TQ9w6uVUBr"},"outputs":[],"source":["### rms energy, my code\n","\n","def rms_calculator(data):\n","    soma = 0\n","    for sample in data:\n","        soma += sample**2\n","    return (soma/len(data))**0.5\n","\n","def frame_2_rms(data,frame_size,hop_lenght):\n","    lista_rms = []\n","    for i in range(0,len(data) - frame_size + 1,hop_lenght):\n","        frame = data[i:i + frame_size]\n","        frame = frame*hann_wnd\n","        rms_value = rms_calculator(data=frame)\n","        lista_rms.append(rms_value)\n","    return np.array(lista_rms)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KTzHl8Uwoaey"},"outputs":[],"source":["\n","for arquivo in arquivos_emg:\n","  filt_values = dfs_emg_module[arquivo][\"filtered\"]\n","  rms = frame_2_rms(data=filt_values, frame_size=FRAME_SIZE, hop_lenght=HOP_LENGTH)\n","  dfs_emg_module[arquivo]['features']['rms'] = rms"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kO4dpQnpOp2P"},"outputs":[],"source":["for arquivo in arquivos_emg:\n","  rms = dfs_emg_module[arquivo]['features'][\"rms\"]\n","  adc_valus = dfs_emg_module[arquivo][\"filtered\"]\n","  sr = dfs_emg_module[arquivo][\"sr\"]\n","  t = np.arange(len(rms)) * HOP_LENGTH / sr\n","  # Cria subplots\n","  fig = go.Figure()\n","\n","  # ECG filtrado\n","  fig.add_trace(go.Scatter(x=np.arange(len(adc_valus))/sr, y=adc_valus,\n","                          mode='lines', name='EMG', line=dict(color='blue'), opacity=0.5))\n","\n","  # Envelope sobreposto\n","  fig.add_trace(go.Scatter(x=t, y=rms,\n","                          mode='lines', name='RMS', line=dict(color='red', width=2)))\n","\n","  fig.update_layout(title=arquivo)\n","\n","  fig.show()"]},{"cell_type":"markdown","metadata":{"id":"ZTiAcgdtQfSN"},"source":["## Zero Crossing Rate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b6hfd7SKggIS"},"outputs":[],"source":["### implementing zero-crossing rate\n","\n","\n","def zero_cs_sum(frame):\n","    count = 0\n","    for n in range(len(frame)-1):\n","        count += 0.5 * (abs(np.sign(frame[n]) - np.sign(frame[n+1])))\n","    return count / (len(frame)-1)  # agora é taxa (0..1)\n","\n","\n","def zcr_calculator(data,frame_size,hop_lenght):\n","    lista_zc = []\n","    for i in range(0,len(data) - frame_size + 1,hop_lenght):\n","        frame = data[i:i + frame_size]\n","        frame = frame*hann_wnd\n","        zc_value = zero_cs_sum(frame=frame)\n","        lista_zc.append(zc_value)\n","    return np.array(lista_zc)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HDMFue0MQunF"},"outputs":[],"source":["for arquivo in arquivos_emg:\n","  filt_values = dfs_emg_module[arquivo][\"filtered\"]\n","  zcr = zcr_calculator(data=filt_values, frame_size=FRAME_SIZE, hop_lenght=HOP_LENGTH,)\n","  dfs_emg_module[arquivo]['features'][\"zcr\"] = zcr"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vDAlGQVTPf3r"},"outputs":[],"source":["for arquivo in arquivos_emg:\n","  zcr = dfs_emg_module[arquivo]['features'][\"zcr\"]\n","  adc_valus = dfs_emg_module[arquivo][\"filtered\"]\n","  sr = dfs_emg_module[arquivo][\"sr\"]\n","  t = np.arange(len(zcr)) * HOP_LENGTH / sr\n","  # Cria subplots\n","  fig = go.Figure()\n","\n","  # ECG filtrado\n","  #fig.add_trace(go.Scatter(x=np.arange(len(adc_valus))/sr, y=adc_valus,\n","     #                     mode='lines', name='EMG', line=dict(color='blue'), opacity=0.5))\n","\n","  # Envelope sobreposto\n","  fig.add_trace(go.Scatter(x=t, y=zcr,\n","                          mode='lines', name='ZCR', line=dict(color='red', width=2)))\n","\n","  fig.update_layout(title=arquivo)\n","\n","  fig.show()"]},{"cell_type":"markdown","metadata":{"id":"h_jVI44t6nMo"},"source":["## Spectograma"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eOVHvVba7GkZ"},"outputs":[],"source":["def plot_spectrogram(Y, sr, hop_length, arquivo,y_axis=\"linear\", vmin=None, vmax=None):\n","    plt.figure(figsize=(25, 10))\n","    librosa.display.specshow(Y,\n","                             sr=sr,\n","                             hop_length=hop_length,\n","                             x_axis=\"time\",\n","                             y_axis=y_axis,\n","                             vmin=vmin,\n","                             vmax=vmax,cmap=\"inferno\")  # <- controla o range de cores\n","    plt.title(arquivo)\n","    plt.colorbar(format=\"%+2.f\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2DZUCDqI7QUY"},"outputs":[],"source":["for arquivo in arquivos_emg:\n","  filt_values = dfs_emg_module[arquivo][\"filtered\"]\n","  S_emg = librosa.stft(y=filt_values, n_fft=FRAME_SIZE, hop_length=HOP_LENGTH,window='hann')\n","  Y_emg = librosa.power_to_db(np.abs(S_emg) ** 2)\n","\n","  dfs_emg_module[arquivo]['Spectograma'] = {\"S_emg\":S_emg,\"Y_emg\":Y_emg}\n","\n","  vmin = Y_emg.min()\n","  vmax = Y_emg.max()\n","\n","  plot_spectrogram(Y_emg, sr, HOP_LENGTH, y_axis=\"log\", vmin=vmin, vmax=vmax, arquivo=arquivo)"]},{"cell_type":"markdown","metadata":{"id":"p1KKdm_DRm_b"},"source":["## Band Energy Ratio"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lt8cUN11Rosy"},"outputs":[],"source":["def calculate_split_frequency_bin(split_frequency, sample_rate, num_frequency_bins):\n","    \"\"\"Infer the frequency bin associated to a given split frequency.\"\"\"\n","\n","    frequency_range = sample_rate / 2\n","    frequency_delta_per_bin = frequency_range / num_frequency_bins\n","    split_frequency_bin = math.floor(split_frequency / frequency_delta_per_bin)\n","    return int(split_frequency_bin)\n","\n","\n","def band_energy_ratio(spectrogram, split_frequency, sample_rate):\n","    \"\"\"Calculate band energy ratio with a given split frequency.\"\"\"\n","\n","    split_frequency_bin = calculate_split_frequency_bin(split_frequency, sample_rate,spectrogram.shape[0])\n","    band_energy_ratio = []\n","\n","    # calculate power spectrogram\n","    power_spectrogram = np.abs(spectrogram) ** 2\n","    power_spectrogram = power_spectrogram.T\n","\n","    # calculate BER value for each frame\n","    for frame in power_spectrogram:\n","        sum_power_low_frequencies = frame[:split_frequency_bin].sum()\n","        sum_power_high_frequencies = frame[split_frequency_bin:].sum()\n","        #print(sum_power_low_frequencies,sum_power_high_frequencies)\n","        epsilon = 1e-12\n","        band_energy_ratio_current_frame = sum_power_low_frequencies / (sum_power_high_frequencies + epsilon)\n","\n","        band_energy_ratio.append(band_energy_ratio_current_frame)\n","\n","\n","    return np.array(band_energy_ratio)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kZd3O6pBRpix"},"outputs":[],"source":["split_frequency = 70\n","\n","\n","for arquivo in arquivos_emg:\n","  S_ecg = dfs_emg_module[arquivo][\"Spectograma\"][\"S_emg\"]\n","  sr = dfs_emg_module[arquivo][\"sr\"]\n","  ber_emg = band_energy_ratio(S_ecg, split_frequency, sr)\n","  dfs_emg_module[arquivo]['features'][\"Band Energy Ratio\"] = ber_emg\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TZjCRfLqp2xH"},"outputs":[],"source":["for arquivo in arquivos_emg:\n","  ber = dfs_emg_module[arquivo]['features'][\"Band Energy Ratio\"]\n","  sr = dfs_emg_module[arquivo][\"sr\"]\n","  t = np.arange(len(ber)) * HOP_LENGTH / sr\n","  # Cria subplots\n","  fig = go.Figure()\n","\n","\n","  # Envelope sobreposto\n","  fig.add_trace(go.Scatter(x=t, y=ber,\n","                          mode='lines', name='Bend Energy Ratio', line=dict(color='red', width=2)))\n","\n","  fig.update_layout(title=arquivo)\n","\n","  fig.show()"]},{"cell_type":"markdown","metadata":{"id":"AjaP-1jFrEli"},"source":["# Spectral Centroid"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SMLAuQtfrHfk"},"outputs":[],"source":["\n","for arquivo in arquivos_emg:\n","  filt_values = dfs_emg_module[arquivo][\"filtered\"]\n","  sr = dfs_emg_module[arquivo][\"sr\"]\n","  sc = librosa.feature.spectral_centroid(y=filt_values, sr=sr, n_fft=FRAME_SIZE, hop_length=HOP_LENGTH,window=\"hann\")[0]\n","\n","  dfs_emg_module[arquivo]['features'][\"Spectral Centroid\"] = sc\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qslT6B-Irgh7"},"outputs":[],"source":["for arquivo in arquivos_emg:\n","  sc = dfs_emg_module[arquivo]['features'][\"Spectral Centroid\"]\n","  sr = dfs_emg_module[arquivo][\"sr\"]\n","  t = np.arange(len(sc)) * HOP_LENGTH / sr\n","  # Cria subplots\n","  fig = go.Figure()\n","\n","\n","  # Envelope sobreposto\n","  fig.add_trace(go.Scatter(x=t, y=sc,\n","                          mode='lines', name='Spectral Centroid', line=dict(color='red', width=2)))\n","\n","  fig.update_layout(title=arquivo)\n","\n","  fig.show()"]},{"cell_type":"markdown","metadata":{"id":"wRjYFJM3r5cI"},"source":["# Bandwidth"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vc2VtGECr8HD"},"outputs":[],"source":["\n","for arquivo in arquivos_emg:\n","  filt_values = dfs_emg_module[arquivo][\"filtered\"]\n","  sr = dfs_emg_module[arquivo][\"sr\"]\n","  bw = librosa.feature.spectral_bandwidth(y=filt_values, sr=sr, n_fft=FRAME_SIZE, hop_length=HOP_LENGTH,window='hann')[0]\n","  dfs_emg_module[arquivo]['features'][\"Bandwidth\"] = bw\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q9SzgH4CsJtY"},"outputs":[],"source":["for arquivo in arquivos_emg:\n","  bw = dfs_emg_module[arquivo]['features'][\"Bandwidth\"]\n","  sr = dfs_emg_module[arquivo][\"sr\"]\n","  t = np.arange(len(bw)) * HOP_LENGTH / sr\n","  # Cria subplots\n","  fig = go.Figure()\n","\n","\n","  # Envelope sobreposto\n","  fig.add_trace(go.Scatter(x=t, y=bw,\n","                          mode='lines', name='Spectral Centroid', line=dict(color='red', width=2)))\n","\n","  fig.update_layout(title=arquivo)\n","\n","  fig.show()"]},{"cell_type":"markdown","metadata":{"id":"-jCupTE2sZO9"},"source":["# f0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VYDXJlpxsa2G"},"outputs":[],"source":["import numpy as np\n","\n","def peak_frequency(signal, sr, frame_size, hop_length):\n","    \"\"\"\n","    Calcula a frequência de pico e magnitude para cada frame do sinal.\n","\n","    Parâmetros:\n","    -----------\n","    signal : np.array\n","        Sinal 1D\n","    sr : int\n","        Taxa de amostragem\n","    frame_size : int\n","        Tamanho de cada frame (em samples)\n","    hop_length : int\n","        Salto entre frames (em samples)\n","\n","    Retorna:\n","    --------\n","    peak_freqs : np.array\n","        Frequência de pico de cada frame\n","    peak_mags : np.array\n","        Magnitude correspondente de cada frame\n","    \"\"\"\n","    n_samples = len(signal)\n","    frames = []\n","\n","    # Cria frames com overlap\n","    for start in range(0, n_samples - frame_size + 1, hop_length):\n","        frames.append(signal[start:start+frame_size])\n","    frames = np.array(frames)\n","\n","    # Arrays de saída\n","    peak_freqs = np.zeros(len(frames))\n","    peak_mags = np.zeros(len(frames))\n","\n","    # Calcula FFT para cada frame\n","    for i, frame in enumerate(frames):\n","        frame = frame*hann_wnd\n","        X = np.fft.fft(frame)\n","        X_mag = np.abs(X)[:frame_size // 2]  # metade positiva\n","        sum_mag = sum(X_mag)\n","        freqs = np.fft.fftfreq(frame_size, d=1/sr)[:frame_size // 2]\n","        idx = np.argmax(X_mag)\n","        peak_freqs[i] = freqs[idx]\n","        peak_mags[i] = X_mag[idx]\n","        peak_mags_norm = (peak_mags/sum_mag)*100\n","    return peak_freqs, peak_mags_norm\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9ESfsJkAtcYz"},"outputs":[],"source":["for arquivo in arquivos_emg:\n","  filt_values = dfs_emg_module[arquivo][\"filtered\"]\n","  sr = dfs_emg_module[arquivo][\"sr\"]\n","  f0,X_f0 = peak_frequency(signal=filt_values, sr=sr, frame_size=FRAME_SIZE, hop_length=HOP_LENGTH)\n","  dfs_emg_module[arquivo]['features'][\"f0\"] = f0\n","  dfs_emg_module[arquivo]['features'][\"Mag_norm_f0\"] = X_f0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7yii08XAvI4c"},"outputs":[],"source":["for arquivo in arquivos_emg:\n","  f0 = dfs_emg_module[arquivo]['features'][\"f0\"]\n","  X_mag_f0 = dfs_emg_module[arquivo]['features'][\"Mag_norm_f0\"]\n","  sr = dfs_emg_module[arquivo][\"sr\"]\n","  t = np.arange(len(f0)) * HOP_LENGTH / sr\n","  # Cria subplots\n","  fig = go.Figure()\n","\n","\n","  # Envelope sobreposto\n","  fig.add_trace(go.Scatter(x=t, y=f0,\n","                          mode='lines', name='f0', line=dict(color='red', width=2)))\n","\n","  fig.add_trace(go.Scatter(x=t, y=X_mag_f0,\n","                          mode='lines', name='Mag Norm f0', line=dict(color='red', width=2)))\n","\n","  fig.update_layout(title=arquivo)\n","\n","  fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C_NEgEghx-H9"},"outputs":[],"source":["arquivos_emg"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nTqcz715xOAb"},"outputs":[],"source":["#for data in arquivos_emg[:]:\n","#  valor = dfs_emg_module[data][\"df\"].valor_ADC.values\n","#  valor = valor - valor.mean()\n","#  # Butterworth bandstop como Second-Order Sections\n","#  sos = signal.butter(N=8, Wn=[20, 500], btype='bandpass', fs=dfs_emg_module[data][\"sr\"], output='sos')\n","#\n","#  # Aplica o filtro\n","#  filtered = signal.sosfiltfilt(sos = sos, x = valor)\n","#\n","#  # Butterworth bandstop como Second-Order Sections\n","#\n","#  #sos = signal.butter(N=8, Wn=[160, 168], btype='bandstop', fs=dfs_emg_module[data][\"sr\"], output='sos')\n","#\n","#  # Aplica o filtro\n","#  #filtered_2 = signal.sosfiltfilt(sos = sos, x = filtered)\n","#\n","#\n","#  dfs_emg_module[data][\"filtered\"] = filtered\n","#  plot_magnitude_spectrum(dfs_emg_module[data][\"filtered\"][10*FRAME_SIZE:12*FRAME_SIZE] ,dfs_emg_module[data][\"sr\"],data,norm=1)"]},{"cell_type":"markdown","metadata":{"id":"Oh3paXvtzf0T"},"source":["# Potencia Hamônicos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XnZ2aMogyPdL"},"outputs":[],"source":["def band_power(f1, f2, freqs, total_power, P):\n","    idx = np.logical_and(freqs >= f1, freqs <= f2)\n","    return np.sum(P[idx]) / total_power if total_power != 0 else 0\n","\n","def features_harmonicos(signal, sr, frame_size, hop_length):\n","    n_samples = len(signal)\n","    frames = []\n","\n","    # Cria frames com overlap\n","    for start in range(0, n_samples - frame_size + 1, hop_length):\n","        frames.append(signal[start:start+frame_size])\n","    frames = np.array(frames)\n","\n","    arrays = {\n","        \"bp_50_150\": np.zeros(len(frames)),\n","        \"bp_150_200\": np.zeros(len(frames)),\n","        \"bp_200_300\": np.zeros(len(frames)),\n","        \"bp_300_500\": np.zeros(len(frames)),\n","        \"bp_novo\": np.zeros(len(frames)),\n","        \"bp_1_harm\": np.zeros(len(frames)),\n","        \"bp_2_harm\": np.zeros(len(frames)),\n","        \"bp_3_harm\": np.zeros(len(frames)),\n","        \"bp_4_harm\": np.zeros(len(frames)),\n","        \"harm_energy\": np.zeros(len(frames)),\n","        \"noise_energy\": np.zeros(len(frames)),\n","        \"hnr\": np.zeros(len(frames)),\n","        \"mdf\": np.zeros(len(frames)),\n","        \"mnf\": np.zeros(len(frames)),\n","    }\n","\n","    for i, frame in enumerate(frames):\n","        frame = frame*hann_wnd\n","        X = np.fft.fft(frame)\n","        X_mag = np.abs(X)[:frame_size // 2]\n","        P = X_mag**2\n","        total_power = np.sum(P)\n","        freqs = np.fft.fftfreq(frame_size, d=1/sr)[:frame_size // 2]\n","\n","        bp_50_150 = band_power(0, 50, freqs, total_power, P)\n","        bp_150_200 = band_power(70, 110, freqs, total_power, P)\n","        bp_200_300 = band_power(130, 170, freqs, total_power, P)\n","        bp_300_500 = band_power(190, 230, freqs, total_power, P)\n","        bp_novo = band_power(250, 500, freqs, total_power, P)\n","\n","        bp_1_harm = band_power(50, 70, freqs, total_power, P)\n","        bp_2_harm = band_power(110, 130, freqs, total_power, P)\n","        bp_3_harm = band_power(170, 190, freqs, total_power, P)\n","        bp_4_harm = band_power(230, 250, freqs, total_power, P)\n","\n","\n","\n","        harm_energy = bp_1_harm + bp_2_harm + bp_3_harm + bp_4_harm\n","        noise_energy = bp_50_150 + bp_150_200 + bp_200_300 + bp_300_500 + bp_novo\n","        hnr = (harm_energy / (noise_energy + 1e-12)) * 100\n","\n","        cumsum = np.cumsum(P)\n","        mdf = freqs[np.searchsorted(cumsum, cumsum[-1] / 2)]\n","        mnf = np.sum(freqs * P) / (np.sum(P) + 1e-12)\n","\n","        arrays[\"bp_50_150\"][i] = bp_50_150\n","        arrays[\"bp_150_200\"][i] = bp_150_200\n","        arrays[\"bp_200_300\"][i] = bp_200_300\n","        arrays[\"bp_300_500\"][i] = bp_300_500\n","        arrays[\"bp_novo\"][i] = bp_novo\n","        arrays[\"bp_1_harm\"][i] = bp_1_harm\n","        arrays[\"bp_2_harm\"][i] = bp_2_harm\n","        arrays[\"bp_3_harm\"][i] = bp_3_harm\n","        arrays[\"bp_4_harm\"][i] = bp_4_harm\n","        arrays[\"harm_energy\"][i] = harm_energy\n","        arrays[\"noise_energy\"][i] = noise_energy\n","        arrays[\"hnr\"][i] = hnr\n","        arrays[\"mdf\"][i] = mdf\n","        arrays[\"mnf\"][i] = mnf\n","\n","    return arrays\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dl8vdO18FL7C"},"outputs":[],"source":["for arquivo in arquivos_emg:\n","  filt_values = dfs_emg_module[arquivo][\"filtered\"]\n","  sr = dfs_emg_module[arquivo][\"sr\"]\n","  arrays = features_harmonicos(signal=filt_values, sr=sr, frame_size=FRAME_SIZE, hop_length=HOP_LENGTH)\n","  dfs_emg_module[arquivo][\"features\"] = dfs_emg_module[arquivo][\"features\"] | arrays"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c6sjjuvOF6bX"},"outputs":[],"source":["# Lista das features que você quer plotar\n","freq_features = [\n","    \"bp_50_150\", \"bp_150_200\", \"bp_200_300\", \"bp_300_500\",\"bp_novo\",\n","    \"bp_1_harm\", \"bp_2_harm\", \"bp_3_harm\",\"bp_4_harm\",\n","    \"harm_energy\", \"noise_energy\", \"hnr\", \"mdf\", \"mnf\"\n","]\n","\n","for arquivo in arquivos_emg:\n","    sr = dfs_emg_module[arquivo][\"sr\"]\n","    features = dfs_emg_module[arquivo][\"features\"]\n","\n","    # Número de frames (assume que todas as features têm o mesmo tamanho)\n","    n_frames = len(features[freq_features[0]])\n","    t = np.arange(n_frames) * HOP_LENGTH / sr\n","\n","    # Cria figura\n","    fig = go.Figure()\n","\n","    # Adiciona cada feature de frequência\n","    colors = ['blue','green','orange','purple','brown','pink','gray','cyan','magenta','lime','teal','olive']\n","    for i, feature_name in enumerate(freq_features):\n","        fig.add_trace(go.Scatter(\n","            x=t,\n","            y=features[feature_name],\n","            mode='lines',\n","            name=feature_name,\n","            line=dict(color=colors[i % len(colors)], width=2)\n","        ))\n","\n","    # Adiciona envelope de f0 se existir\n","    if \"f0\" in dfs_emg_module[arquivo]:\n","        f0 = dfs_emg_module[arquivo][\"f0\"]\n","        X_mag_f0 = dfs_emg_module[arquivo][\"X_mag_f0\"]\n","        fig.add_trace(go.Scatter(\n","            x=t,\n","            y=f0,\n","            mode='lines',\n","            name='f0',\n","            line=dict(color='red', width=2)\n","        ))\n","        fig.add_trace(go.Scatter(\n","            x=t,\n","            y=X_mag_f0,\n","            mode='lines',\n","            name='Mag Norm f0',\n","            line=dict(color='red', width=2, dash='dot')\n","        ))\n","\n","    fig.update_layout(\n","        title=arquivo,\n","        xaxis_title='Tempo [s]',\n","        yaxis_title='Valor da Feature'\n","    )\n","\n","    fig.show()\n"]},{"cell_type":"markdown","metadata":{"id":"aW_NLLGL5IA6"},"source":["# Mais Features no Tempo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8v455BW05LTB"},"outputs":[],"source":["import numpy as np\n","\n","def outras_features_tempo(signal, sr, frame_size, hop_length):\n","    n_samples = len(signal)\n","    frames = []\n","\n","    # Cria frames com overlap\n","    for start in range(0, n_samples - frame_size + 1, hop_length):\n","        frames.append(signal[start:start+frame_size])\n","    frames = np.array(frames)\n","\n","    # Inicializa arrays de saída\n","    arrays = {\n","        \"mav\": np.zeros(len(frames)),\n","        \"wl\": np.zeros(len(frames)),\n","        \"mean_v\": np.zeros(len(frames)),\n","        \"std_v\": np.zeros(len(frames)),\n","        \"var_v\": np.zeros(len(frames)),\n","        \"ssc\": np.zeros(len(frames)),\n","        \"mavs\": np.zeros(len(frames))  # MAV ponderada\n","    }\n","\n","    # Calcula features para cada frame\n","    for i, frame in enumerate(frames):\n","        frame = frame*hann_wnd\n","        mav = np.mean(np.abs(frame))                         # Mean Absolute Value\n","        wl = np.sum(np.abs(np.diff(frame)))                  # Waveform Length\n","        mean_v = np.mean(frame)                              # Média\n","        std_v = np.std(frame)                                # Desvio padrão\n","        var_v = np.var(frame)                                # Variância\n","        ssc = np.sum(np.diff(np.sign(np.diff(frame))) != 0)  # Slope Sign Changes\n","\n","        # MAV ponderada (MAVS) - exemplo simples: pondera central do frame\n","        weights = np.linspace(0.5, 1.5, len(frame))\n","        mavs = np.mean(np.abs(frame) * weights)\n","\n","        arrays[\"mav\"][i] = mav\n","        arrays[\"wl\"][i] = wl\n","        arrays[\"mean_v\"][i] = mean_v\n","        arrays[\"std_v\"][i] = std_v\n","        arrays[\"var_v\"][i] = var_v\n","        arrays[\"ssc\"][i] = ssc\n","        arrays[\"mavs\"][i] = mavs\n","\n","    return arrays\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CIrT0xgp-BND"},"outputs":[],"source":["for arquivo in arquivos_emg:\n","  filt_values = dfs_emg_module[arquivo][\"filtered\"]\n","  sr = dfs_emg_module[arquivo][\"sr\"]\n","  arrays = outras_features_tempo(signal=filt_values, sr=sr, frame_size=FRAME_SIZE, hop_length=HOP_LENGTH)\n","  dfs_emg_module[arquivo][\"features\"] = dfs_emg_module[arquivo][\"features\"] | arrays"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"11-fcKUrGaFj"},"outputs":[],"source":["# Lista das features de tempo que queremos plotar\n","tempo_features = [\"mav\", \"wl\", \"mean_v\", \"std_v\", \"var_v\", \"ssc\", \"mavs\"]\n","\n","for arquivo in arquivos_emg:\n","    sr = dfs_emg_module[arquivo][\"sr\"]\n","    features = dfs_emg_module[arquivo][\"features\"]\n","\n","    # Número de frames (assume que todas as features têm o mesmo tamanho)\n","    n_frames = len(features[tempo_features[0]])\n","    t = np.arange(n_frames) * HOP_LENGTH / sr\n","\n","    # Cria figura\n","    fig = go.Figure()\n","\n","    # Adiciona cada feature do tempo\n","    colors = ['blue','green','orange','purple','brown','pink','gray','cyan']\n","    for i, feature_name in enumerate(tempo_features):\n","        fig.add_trace(go.Scatter(\n","            x=t,\n","            y=features[feature_name],\n","            mode='lines',\n","            name=feature_name,\n","            line=dict(color=colors[i % len(colors)], width=2)\n","        ))\n","\n","    fig.update_layout(\n","        title=f\"{arquivo} - Features do Tempo\",\n","        xaxis_title='Tempo [s]',\n","        yaxis_title='Valor da Feature'\n","    )\n","\n","    fig.show()\n"]},{"cell_type":"markdown","metadata":{"id":"QjIf0h-YHk-9"},"source":["# Features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tjyPTmGKHf2k"},"outputs":[],"source":["dfs_emg_module[arquivo][\"features\"].keys()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q0JaYJr7BTYD"},"outputs":[],"source":["time_features = ['amp_en', 'rms', 'zcr','mav', 'wl', 'mean_v', 'std_v', 'var_v', 'ssc', 'mavs']\n","freq_features = ['Band Energy Ratio', 'Spectral Centroid', 'Bandwidth', 'f0', 'Mag_norm_f0', 'bp_50_150', 'bp_150_200', 'bp_200_300',\n","\t'bp_300_500', 'bp_1_harm', 'bp_2_harm', 'bp_3_harm', 'harm_energy', 'noise_energy', 'hnr', 'mdf', 'mnf']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y21G2EYtHpxg"},"outputs":[],"source":["from sklearn.preprocessing import MinMaxScaler\n","\n","\n","## Dicionário de features relevantes por arquivo\n","#features_relevantes = {\n","#    \"emg__modulo_1_abre_fecha.csv\": [\n","#        \"amp_en\", \"rms\", \"Mag_norm_f0\", \"mdf\", \"mnf\", \"bp_50_150\",\n","#        \"mav\", \"wl\", \"mean_v\", \"std_v\", \"var_v\", \"mavs\", \"Spectral Centroid\"\n","#    ],\n","#    \"emg__modulo_1_abre_fecha_2.csv\": [\n","#        \"amp_en\", \"rms\", \"Mag_norm_f0\", \"harm_energy\", \"noise_energy\", \"hnr\", \"mdf\",\n","#        \"mav\", \"wl\", \"mean_v\", \"std_v\", \"var_v\", \"ssc\",\"mavs\"\n","#    ],\n","#    \"emg__modulo_1_abre_fecha_variando.csv\": [\n","#        \"amp_en\", \"rms\", \"Mag_norm_f0\", \"harm_energy\", \"noise_energy\", \"hnr\", \"mdf\",\n","#        \"mav\", \"wl\", \"mean_v\", \"std_v\", \"var_v\", \"ssc\", \"mavs\"\n","#    ]\n","#}\n","\n","for arquivo in arquivos_emg:\n","    # Pega as features do arquivo atual\n","    features = list(dfs_emg_module[arquivo][\"features\"].keys())\n","\n","    # Filtra e Ajusta as features\n","    dfs_emg_module[arquivo][\"features_filtered\"] = {}\n","    for f in features:\n","      value = dfs_emg_module[arquivo][\"features\"][f][:]\n","\n","\n","      value = simple_moving_average(data = value,window_size=1)\n","      value = median_clean(signal = value, kernel_size=3)\n","\n","      #value = value ** 2\n","\n","      dfs_emg_module[arquivo][\"features_filtered\"][f] = value\n","\n","    # Encontra o tamanho mínimo entre as features\n","    len_min = min(len(dfs_emg_module[arquivo][\"features_filtered\"][f]) for f in features)\n","\n","    # Trunca todas as features para o mesmo tamanho\n","    features_truncadas = [dfs_emg_module[arquivo][\"features_filtered\"][f][:len_min] for f in features]\n","\n","    # Junta em uma matriz (frames x features)\n","    dfs_emg_module[arquivo][\"X\"] = np.column_stack(features_truncadas)\n","\n","\n","\n","    # Encontra o tamanho mínimo entre as features\n","    len_min = min(len(dfs_emg_module[arquivo][\"features\"][f]) for f in features)\n","\n","    # Trunca todas as features para o mesmo tamanho\n","    features_brutas_truncadas = [dfs_emg_module[arquivo][\"features\"][f][:len_min] for f in features]\n","\n","    # Junta em uma matriz (frames x features)\n","    dfs_emg_module[arquivo][\"X_Brutas\"] = np.column_stack(features_brutas_truncadas)\n","\n","\n","    # Normaliza\n","    scaler = MinMaxScaler()\n","    dfs_emg_module[arquivo][\"X_scaled\"] = scaler.fit_transform(dfs_emg_module[arquivo][\"X\"])\n","    print(f\"{arquivo}: matriz de features -> {dfs_emg_module[arquivo]['X_scaled'].shape}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ca1eFlnpQCtG"},"outputs":[],"source":["## Todos os Arquivos\n","\n","for arquivo in arquivos_emg:\n","    sr = dfs_emg_module[arquivo][\"sr\"]\n","    #features = features_relevantes[arquivo]\n","    features = list(dfs_emg_module[arquivo][\"features_filtered\"].keys())\n","    # Obtém matriz normalizada e tamanho\n","    X_scaled = dfs_emg_module[arquivo][\"X_scaled\"]\n","    n_frames = X_scaled.shape[0]\n","    t = np.arange(n_frames) * HOP_LENGTH / sr\n","\n","    # Cria figura\n","    fig = go.Figure()\n","\n","    # Paleta de cores\n","    colors = ['blue', 'green', 'orange', 'purple', 'brown', 'pink', 'gray',\n","              'cyan', 'magenta', 'lime', 'teal', 'olive', 'navy', 'gold', 'maroon']\n","\n","    # Adiciona cada feature normalizada\n","    for i, feature_name in enumerate(features):\n","        fig.add_trace(go.Scatter(\n","            x=t,\n","            y=X_scaled[:, i],\n","            mode='lines',\n","            name=feature_name,\n","            line=dict(color=colors[i % len(colors)], width=2)\n","        ))\n","\n","    fig.update_layout(\n","        title=f\"{arquivo} — Features Normalizadas\",\n","        xaxis_title=\"Tempo [s]\",\n","        yaxis_title=\"Valor Normalizado (0–1)\",\n","        height=600\n","        #legend=dict(orientation='v', yanchor='bottom', y=-0.3, xanchor='center', x=0.5)\n","    )\n","\n","    fig.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iff5xwGVcoiz"},"outputs":[],"source":["## APENAS O ABRE FECHA\n","\n","for arquivo in arquivos_abre_fecha_emg:\n","    sr = dfs_emg_module[arquivo][\"sr\"]\n","    #features = features_relevantes[arquivo]\n","    features = list(dfs_emg_module[arquivo][\"features_filtered\"].keys())\n","    # Obtém matriz normalizada e tamanho\n","    X_scaled = dfs_emg_module[arquivo][\"X_scaled\"]\n","    n_frames = X_scaled.shape[0]\n","    t = np.arange(n_frames) * HOP_LENGTH / sr\n","\n","    # Cria figura\n","    fig = go.Figure()\n","\n","    # Paleta de cores\n","    colors = ['blue', 'green', 'orange', 'purple', 'brown', 'pink', 'gray',\n","              'cyan', 'magenta', 'lime', 'teal', 'olive', 'navy', 'gold', 'maroon']\n","\n","    # Adiciona cada feature normalizada\n","    for i, feature_name in enumerate(features):\n","        fig.add_trace(go.Scatter(\n","            x=t,\n","            y=X_scaled[:, i],\n","            mode='lines',\n","            name=feature_name,\n","            line=dict(color=colors[i % len(colors)], width=2)\n","        ))\n","\n","    fig.update_layout(\n","        title=f\"{arquivo} — Features Normalizadas\",\n","        xaxis_title=\"Tempo [s]\",\n","        yaxis_title=\"Valor Normalizado (0–1)\",\n","        height=600\n","        #legend=dict(orientation='v', yanchor='bottom', y=-0.3, xanchor='center', x=0.5)\n","    )\n","\n","    fig.show()\n"]},{"cell_type":"markdown","metadata":{"id":"LYWAaI-1Xo_I"},"source":["#PCA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vBG1gM5fWBCY"},"outputs":[],"source":["\n","for arquivo in arquivos_abre_fecha_emg:\n","    # Lista de features relevantes\n","    #selected_features = features_relevantes[arquivo]\n","    all_features = list(dfs_emg_module[arquivo][\"features\"].keys())\n","\n","    # Encontra os índices das features relevantes\n","    #selected_indices = [all_features.index(f) for f in selected_features]\n","\n","    # Seleciona colunas de X_scaled correspondentes às features relevantes\n","    X_scaled_relevante = dfs_emg_module[arquivo][\"X_scaled\"]\n","\n","    # Aplica PCA\n","    pca = PCA(n_components=2)\n","    X_pca = pca.fit_transform(X_scaled_relevante)\n","\n","    # Plot\n","    plt.figure(figsize=(8,5))\n","    plt.scatter(X_pca[:,0], X_pca[:,1], s=5, alpha=0.7)\n","    plt.xlabel(\"PC1\")\n","    plt.ylabel(\"PC2\")\n","    plt.title(f\"PCA 2D - {arquivo} - Todas as Features\")\n","    plt.grid(True)\n","    plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"e3dc_IRjZb1F"},"source":["# Cluster"]},{"cell_type":"markdown","metadata":{"id":"DhNOhfVGXLE5"},"source":["## KMeans"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GBK2-QtfGtGY"},"outputs":[],"source":["# teste_features = [\"amp_en\",\"rms\",\"Band Energy Ratio\",\"Spectral Centroid\", \"Bandwidth\", \"f0\", \"Mag_norm_f0\", \"bp_50_150\", \"bp_300_500\", \"mdf\", \"mnf\", 'wl', \"mean_v\", \"std_v\", \"ssc\", \"mavs\"]\n","\n","teste_features = [\n","    \"rms\", \"Band Energy Ratio\", \"Spectral Centroid\",\n","    \"Mag_norm_f0\", \"bp_50_150\", \"mdf\", \"mnf\", \"mav\",\n","    \"wl\", \"std_v\", \"var_v\", \"ssc\", \"mavs\"\n","]\n","\n","teste_features = [\"amp_en\",\"rms\",\"Band Energy Ratio\",\"Spectral Centroid\", \"Bandwidth\", \"f0\",\n","                 \"Mag_norm_f0\", \"bp_50_150\", \"bp_300_500\", \"mdf\", \"mnf\", 'wl',\n","                \"mean_v\", \"std_v\", \"ssc\", \"mavs\"]\n","\n","\n","teste_features = ['rms', 'Spectral Centroid', 'Bandwidth', 'f0', 'Mag_norm_f0','mav', 'wl',\n"," 'mean_v', 'std_v', 'var_v', 'ssc', 'mavs']\n","\n","\n","teste_features = [ 'rms','mav', 'wl', 'std_v', 'var_v','mavs']\n","\n","teste_features = ['amp_en', 'rms','Bandwidth', 'f0','bp_50_150','bp_200_300','bp_300_500','mnf',\n","                 'mav', 'wl','std_v', 'var_v', 'ssc', 'mavs']\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U1tH5zpKgGp0"},"outputs":[],"source":["all_features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sNlUL44fZ-nh"},"outputs":[],"source":["for arquivo in arquivos_abre_fecha_emg:\n","  # Lista de features relevantes\n","\n","  all_features = list(dfs_emg_module[arquivo][\"features_filtered\"].keys())\n","\n","  selected_features = all_features[:]\n","  #selected_features = teste_features[:]\n","  #selected_features =  time_features[:]\n","  #selected_features.remove(\"zcr\")\n","  #selected_features.remove(\"mavs\")\n","  #selected_features.remove(\"mav\")\n","\n","  # Encontra os índices das features relevantes\n","  selected_indices = [all_features.index(f) for f in selected_features]\n","\n","  # Seleciona colunas de X_scaled correspondentes às features relevantes\n","  X_scaled_relevante = dfs_emg_module[arquivo][\"X_scaled\"][:, selected_indices]\n","\n","\n","\n","\n","  kmens = KMeans(n_clusters=2,random_state=42).fit(X_scaled_relevante)\n","  clusters = kmens.labels_\n","  # cria um filtro para evitar valores falsos, sendo uma variacao bem rapida de 4 5 amostras, ai isso nos previne disso\n","\n","  clusters = median_clean(signal=clusters,kernel_size=1)\n","  clusters = run_length_smooth(labels=clusters,min_run_length=7)\n","  clusters = 1 - clusters\n","\n","  dfs_emg_module[arquivo][\"Clusters_Kmeans\"] = clusters\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5sHlb4D4ac3k"},"outputs":[],"source":["#for arquivo in arquivos_abre_fecha_emg[len(arquivos_abre_fecha_emg)//2:]:\n","#  clusters = dfs_emg_module[arquivo][\"Clusters_Kmeans\"]\n","#  print(arquivo)\n","#  print(clusters)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4k8ZKFmS-ToM"},"outputs":[],"source":["for arquivo in arquivos_abre_fecha_emg[:]:\n","    sr = dfs_emg_module[arquivo][\"sr\"]\n","    signal = dfs_emg_module[arquivo][\"filtered_Nao_Causal\"]\n","    clusters = dfs_emg_module[arquivo][\"Clusters_Kmeans\"]\n","\n","    # Número de frames e tamanho de cada frame\n","    n_frames = len(clusters)\n","    frame_times = np.arange(n_frames) * HOP_LENGTH / sr  # tempo inicial de cada frame\n","\n","    # Para plotar clusters no tempo, repetimos o valor do cluster para cada ponto do frame\n","    cluster_signal = np.repeat(clusters, HOP_LENGTH)\n","    cluster_time = np.arange(len(cluster_signal)) / sr  # tempo correspondente\n","\n","    # Ajusta o tamanho para coincidir com o sinal real (em caso de padding final)\n","    #cluster_signal = cluster_signal[:len(signal)]\n","    #cluster_time = cluster_time[:len(signal)]\n","\n","    fig = go.Figure()\n","\n","    # Plot do sinal EMG\n","    fig.add_trace(go.Scatter(\n","        x=np.arange(len(signal))/sr,\n","        y=signal,\n","        mode='lines',\n","        name='EMG',\n","        line=dict(color='blue', width=1)\n","    ))\n","\n","    # Plot do cluster (como linha escalonada)\n","    fig.add_trace(go.Scatter(\n","        x=cluster_time,\n","        y=cluster_signal * np.max(signal),  # escala para coincidir visualmente com o sinal\n","        mode='lines',\n","        name='Cluster',\n","        line=dict(color='red', width=2, dash='dot')\n","    ))\n","\n","    fig.update_layout(\n","        title=f\"{arquivo} — Sinal EMG e Cluster por Frame - Kmeans\",\n","        xaxis_title=\"Tempo [s]\",\n","        yaxis_title=\"Amplitude\",\n","        height=500\n","    )\n","\n","    fig.show()\n"]},{"cell_type":"markdown","metadata":{"id":"YgKySUjoXQZw"},"source":["## Gaussian Mixture Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SoqJqupBXY1w"},"outputs":[],"source":["from sklearn.mixture import GaussianMixture\n","\n","for arquivo in arquivos_abre_fecha_emg:\n","  # Lista de features relevantes\n","\n","  all_features = list(dfs_emg_module[arquivo][\"features_filtered\"].keys())\n","\n","  selected_features = all_features[:]\n","  #selected_features = teste_features[:]\n","  #selected_features =  time_features[:]\n","  #selected_features.remove(\"zcr\")\n","  #selected_features.remove(\"mavs\")\n","  #selected_features.remove(\"mav\")\n","\n","  # Encontra os índices das features relevantes\n","  selected_indices = [all_features.index(f) for f in selected_features]\n","\n","  # Seleciona colunas de X_scaled correspondentes às features relevantes\n","  X_scaled_relevante = dfs_emg_module[arquivo][\"X_scaled\"][:, selected_indices]\n","\n","\n","  n = 2\n","\n","  gmm = GaussianMixture(n_components=n, random_state=42)\n","  gmm.fit(X_scaled_relevante)\n","  clusters = gmm.predict(X_scaled_relevante)\n","\n","  # cria um filtro para evitar valores falsos\n","\n","  #clusters = median_clean(signal=clusters,kernel_size=3)\n","  clusters = run_length_smooth(labels=clusters,min_run_length=15)\n","  #clusters = median_clean(signal=clusters,kernel_size=3)\n","  clusters = 1 - clusters\n","\n","  dfs_emg_module[arquivo][\"Clusters_GMM\"] = clusters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XAKG8H7flgJD"},"outputs":[],"source":["\n","for nome in arquivos_abre_fecha_emg:\n","  if nome == \"emg__modulo_abre_fecha_dedao_resto_aberto_10s_3.csv\":\n","    print(f\"Alterados na mão: Dataset -> {nome} \\n{(len(dfs_emg_module[nome][\"Clusters_GMM\"][423:440])/len(dfs_emg_module[nome][\"Clusters_GMM\"][:]))*100} %\")\n","    # faixa que estão os clusters errados [423:440]\n","    # explicado no final do arquivo\n","    for i in range(423,440):\n","      dfs_emg_module[nome][\"Clusters_GMM\"][i] = 1-dfs_emg_module[nome][\"Clusters_GMM\"][i]\n","\n","  if nome == \"emg__modulo_abre_fecha_dedao_resto_aberto_10s_4.csv\":\n","    print(f\"Alterados na mão: Dataset -> {nome} \\n{(len(dfs_emg_module[nome][\"Clusters_GMM\"][418:431])/len(dfs_emg_module[nome][\"Clusters_GMM\"][:]))*100} %\")\n","    # faixa que estão os clusters errados [418:431]\n","    # explicado no final do arquivo\n","    for i in range(418,431):\n","      dfs_emg_module[nome][\"Clusters_GMM\"][i] = 1-dfs_emg_module[nome][\"Clusters_GMM\"][i]\n","\n","  if nome == \"emg__modulo_abre_fecha_dedao_resto_aberto_10s_5.csv\":\n","    print(f\"Alterados na mão: Dataset -> {nome} \\n{(len(dfs_emg_module[nome][\"Clusters_GMM\"][79:82])/len(dfs_emg_module[nome][\"Clusters_GMM\"][:]))*100} %\")\n","    # faixa que estão os clusters errados [79:82]\n","    # explicado no final do arquivo\n","    for i in range(79,82):\n","      dfs_emg_module[nome][\"Clusters_GMM\"][i] = 1-dfs_emg_module[nome][\"Clusters_GMM\"][i]\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cPF6C0wEXdAh"},"outputs":[],"source":["for arquivo in arquivos_abre_fecha_emg:\n","    sr = dfs_emg_module[arquivo][\"sr\"]\n","    signal = dfs_emg_module[arquivo][\"filtered_Nao_Causal\"]\n","    clusters = dfs_emg_module[arquivo][\"Clusters_GMM\"]\n","\n","    # Número de frames e tamanho de cada frame\n","    n_frames = len(clusters)\n","    frame_times = np.arange(n_frames) * HOP_LENGTH / sr  # tempo inicial de cada frame\n","\n","    # Para plotar clusters no tempo, repetimos o valor do cluster para cada ponto do frame\n","    cluster_signal = np.repeat(clusters, HOP_LENGTH)\n","    cluster_time = np.arange(len(cluster_signal)) / sr  # tempo correspondente\n","\n","    # Ajusta o tamanho para coincidir com o sinal real (em caso de padding final)\n","    cluster_signal = cluster_signal[:len(signal)]\n","    cluster_time = cluster_time[:len(signal)]\n","\n","    fig = go.Figure()\n","\n","    # Plot do sinal EMG\n","    fig.add_trace(go.Scatter(\n","        x=np.arange(len(signal))/sr,\n","        y=signal,\n","        mode='lines',\n","        name='EMG',\n","        line=dict(color='blue', width=1)\n","    ))\n","\n","    # Plot do cluster (como linha escalonada)\n","    fig.add_trace(go.Scatter(\n","        x=cluster_time,\n","        y=cluster_signal * np.max(signal),  # escala para coincidir visualmente com o sinal\n","        mode='lines',\n","        name='Cluster',\n","        line=dict(color='red', width=2, dash='dot')\n","    ))\n","\n","    fig.update_layout(\n","        title=f\"{arquivo} — Sinal EMG e Cluster por Frame - GMM\",\n","        xaxis_title=\"Tempo [s]\",\n","        yaxis_title=\"Amplitude\",\n","        height=500\n","    )\n","\n","    fig.show()\n"]},{"cell_type":"markdown","metadata":{"id":"iwBrgD9OXS-w"},"source":["## DBSCAN (Density-Based Spatial Clustering of Applications with Noise)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yGIWhkIKXQKh"},"outputs":[],"source":["from sklearn.cluster import DBSCAN\n","\n","for arquivo in arquivos_abre_fecha_emg:\n","    #selected_features = features_relevantes[arquivo]\n","    all_features = list(dfs_emg_module[arquivo][\"features_filtered\"].keys())\n","    #selected_indices = [all_features.index(f) for f in selected_features]\n","\n","    #X_scaled_relevante = dfs_emg_module[arquivo][\"X_scaled\"][:, selected_indices]\n","    X_scaled_relevante = dfs_emg_module[arquivo][\"X_scaled\"][:]\n","\n","    # Parâmetros iniciais (ajustáveis)\n","    eps = 1  # distância máxima entre pontos vizinhos\n","    min_samples = 10  # mínimo de pontos para formar um cluster\n","\n","    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n","    clusters = dbscan.fit_predict(X_scaled_relevante)\n","\n","    dfs_emg_module[arquivo][\"Clusters_DBSCAN\"] = clusters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mM0d_1uJXeeK"},"outputs":[],"source":["for arquivo in arquivos_abre_fecha_emg:\n","    sr = dfs_emg_module[arquivo][\"sr\"]\n","    signal = dfs_emg_module[arquivo][\"filtered\"]\n","    clusters = dfs_emg_module[arquivo][\"Clusters_DBSCAN\"]\n","\n","    # Número de frames e tamanho de cada frame\n","    n_frames = len(clusters)\n","    frame_times = np.arange(n_frames) * HOP_LENGTH / sr  # tempo inicial de cada frame\n","\n","    # Para plotar clusters no tempo, repetimos o valor do cluster para cada ponto do frame\n","    cluster_signal = np.repeat(clusters, HOP_LENGTH)\n","    cluster_time = np.arange(len(cluster_signal)) / sr  # tempo correspondente\n","\n","    # Ajusta o tamanho para coincidir com o sinal real (em caso de padding final)\n","    cluster_signal = cluster_signal[:len(signal)]\n","    cluster_time = cluster_time[:len(signal)]\n","\n","    fig = go.Figure()\n","\n","    # Plot do sinal EMG\n","    fig.add_trace(go.Scatter(\n","        x=np.arange(len(signal))/sr,\n","        y=signal,\n","        mode='lines',\n","        name='EMG',\n","        line=dict(color='blue', width=1)\n","    ))\n","\n","    # Plot do cluster (como linha escalonada)\n","    fig.add_trace(go.Scatter(\n","        x=cluster_time,\n","        y=cluster_signal * np.max(signal),  # escala para coincidir visualmente com o sinal\n","        mode='lines',\n","        name='Cluster',\n","        line=dict(color='red', width=2, dash='dot')\n","    ))\n","\n","    fig.update_layout(\n","        title=f\"{arquivo} — Sinal EMG e Cluster por Frame\",\n","        xaxis_title=\"Tempo [s]\",\n","        yaxis_title=\"Amplitude\",\n","        height=500\n","    )\n","\n","    fig.show()\n"]},{"cell_type":"markdown","metadata":{"id":"GLkPLDNBaU7P"},"source":["## Setar Estado"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FidDeq5ZbbZO"},"outputs":[],"source":["len(\"emg__modulo_aberto_\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4oULMy1-bd8e"},"outputs":[],"source":["len(\"emg__modulo_fecha_dedao_resto_aberto_\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ogcz3CYPb9hZ"},"outputs":[],"source":["arquivo[0:19]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ttpeXpnfaUKg"},"outputs":[],"source":["for arquivo in arquivos_abre_fecha_emg:\n","    #selected_features = features_relevantes[arquivo]\n","    all_features = list(dfs_emg_module[arquivo][\"features_filtered\"].keys())\n","    #selected_indices = [all_features.index(f) for f in selected_features\n","    n = len(dfs_emg_module[arquivo][\"X_scaled\"])\n","    if arquivo[:19] == \"emg__modulo_aberto_\":\n","      clusters = np.zeros(n, dtype=int)\n","      print(f\"Arquivo: {arquivo} setado como {clusters}\")\n","    elif arquivo[:37] == \"emg__modulo_fecha_dedao_resto_aberto_\":\n","      clusters = np.ones(n, dtype=int)\n","      print(f\"Arquivo: {arquivo} setado como {clusters}\")\n","    else:\n","      print(f\"Não entrou no IF\")\n","      break\n","\n","    dfs_emg_module[arquivo][\"Label\"] = clusters"]},{"cell_type":"code","source":["dfs_emg_module[arquivo][\"Label\"]"],"metadata":{"id":"m7CkYii7gMuf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MGTaKRFrOajg"},"source":["Aplicar MinMaxScaler apenas para o clustering\n","Isso garante que todas as features tenham o mesmo peso na hora de formar os clusters.\n","\n","\n","Obter os rótulos dos clusters com base nesse dataset escalado.\n","\n","\n","Juntar os rótulos ao dataset original (não escalado)\n","Assim, você preserva os valores reais das features, o que pode ser útil para interpretação, visualização ou uso posterior.\n","\n","\n","Aplicar MinMaxScaler no dataset completo (com os rótulos)\n","Isso pode ser feito se você quiser alimentar um modelo de ML supervisionado depois, por exemplo."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hkP1pGLPudyV"},"outputs":[],"source":["lista_frames = []\n","\n","for arquivo in arquivos_abre_fecha_emg:\n","  signal = dfs_emg_module[arquivo][\"filtered\"]\n","  lista_signal = []\n","  for i in range(0, len(signal) - FRAME_SIZE + 1, HOP_LENGTH):\n","      wnd = signal[i:i+FRAME_SIZE]\n","\n","      lista_signal.append(wnd)\n","  lista_frames.append(lista_signal)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UfmTuu9O1Yus"},"outputs":[],"source":["#rms_calculator(lista_frames[2][-1]*hann_wnd)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"To8dqeXs2HiN"},"outputs":[],"source":["#len(lista_frames[2])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F8ZxofJn5eBu"},"outputs":[],"source":["(len(dfs_emg_module[arquivo][\"filtered\"]))//HOP_LENGTH"]},{"cell_type":"markdown","metadata":{"id":"DcylwVmZfmrP"},"source":["## Features com o Cluster"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q1MnR5orfqSe"},"outputs":[],"source":["## Todos os Arquivos\n","\n","for arquivo in arquivos_emg:\n","    sr = dfs_emg_module[arquivo][\"sr\"]\n","    #features = features_relevantes[arquivo]\n","    #features = time_features[:]\n","    #features.remove(\"zcr\")\n","    #features.remove(\"mavs\")\n","    #features.remove(\"mav\")\n","    features = list(dfs_emg_module[arquivo][\"features_filtered\"].keys())\n","    # Obtém matriz normalizada e tamanho\n","    X_scaled = dfs_emg_module[arquivo][\"X_scaled\"]\n","    n_frames = X_scaled.shape[0]\n","    t = np.arange(n_frames) * HOP_LENGTH / sr\n","\n","    # Cria figura\n","    fig = go.Figure()\n","\n","    # Paleta de cores\n","    colors = ['blue', 'green', 'orange', 'purple', 'brown', 'pink', 'gray',\n","              'cyan', 'magenta', 'lime', 'teal', 'olive', 'navy', 'gold', 'maroon']\n","\n","    # Adiciona cada feature normalizada\n","    for i, feature_name in enumerate(features):\n","        fig.add_trace(go.Scatter(\n","            x=t,\n","            y=X_scaled[:, i],\n","            mode='lines',\n","            name=feature_name,\n","            line=dict(color=colors[i % len(colors)], width=2)\n","        ))\n","    fig.add_trace(go.Scatter(\n","        x=t,\n","        y=dfs_emg_module[arquivo][\"Clusters_Kmeans\"],\n","        mode='lines',\n","        name=\"Kmeans\",\n","        line=dict(color=\"red\", width=2)\n","    ))\n","\n","    fig.add_trace(go.Scatter(\n","        x=t,\n","        y=dfs_emg_module[arquivo][\"Clusters_GMM\"],\n","        mode='lines',\n","        name=\"GMM\",\n","        line=dict(color=\"blue\", width=2)\n","    ))\n","    fig.update_layout(\n","        title=f\"{arquivo} — Features Normalizadas\",\n","        xaxis_title=\"Tempo [s]\",\n","        yaxis_title=\"Valor Normalizado (0–1)\",\n","        height=600\n","        #legend=dict(orientation='v', yanchor='bottom', y=-0.3, xanchor='center', x=0.5)\n","    )\n","\n","    fig.show()\n"]},{"cell_type":"markdown","metadata":{"id":"5cnPKR50uNzl"},"source":["amp_en,rms,Band Energy Ratio,Spectral Centroid,  Mag_norm_f0, bp_50_150, mdf, mnf, wav,wl, std_v,var_v, ssc, mavs"]},{"cell_type":"markdown","metadata":{"id":"nCuh6ZvpTqGk"},"source":["# Salvar"]},{"cell_type":"markdown","metadata":{"id":"sEb9bu7uSDS3"},"source":["## Abre e Fecha"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L3NUTmFSYn29"},"outputs":[],"source":["arquivos_abre_fecha_emg"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"72U77ah8T6i8"},"outputs":[],"source":[" ## Salvar os arquivos abre e fecha\n","\n","from sklearn.metrics import adjusted_rand_score\n","\n","for arquivo in arquivos_abre_fecha_emg:\n","  print(arquivo)\n","  arq_selecionado = input(\"Nome do Arquivo: \\n\")\n","\n","  if arq_selecionado in arquivo:\n","    features_headers = list(dfs_emg_module[arq_selecionado][\"features_filtered\"].keys())\n","    features_headers.extend([\"Label\"])\n","\n","    array_abre_fecha_2 = dfs_emg_module[arq_selecionado][\"X_Brutas\"]\n","    cluster_abre_fecha_2_label = dfs_emg_module[arq_selecionado][\"Label\"]\n","\n","    # converter cluster em coluna (336, 1)\n","    cluster_abre_fecha_2_label = np.array(cluster_abre_fecha_2_label).reshape(-1, 1)\n","\n","    # concatenar lado a lado (axis=1)\n","    concatenado_abre_fecha_2 = np.concatenate((array_abre_fecha_2, cluster_abre_fecha_2_label), axis=1)\n","\n","\n","\n","    print(concatenado_abre_fecha_2.shape)\n","\n","    df_features = pd.DataFrame(concatenado_abre_fecha_2,columns=features_headers)\n","\n","    salvar = input(\"Salvar? (S/N)\")\n","    if salvar == \"S\":\n","      # Salva em CSV\n","      df_features.to_csv(path+\"Features Datasets/\"+arq_selecionado+\"Features.csv\", index=False)\n","      print(\"Arquivo path+'Features Datasets/'\"+arq_selecionado+\"_Features.csv\" +\" salvo com sucesso!\")\n","\n","  else:\n","    print(\"Não Criou o DataFrame\")\n","\n"]},{"cell_type":"code","source":["df_features"],"metadata":{"id":"fhx_l_MuldEW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hsiAk9wGjp4P"},"source":["# Processo de Cluster, Individual:\n","\n","Neste Contexto o importante é entender como otimizar o processo de cluster de cada dataset, neste não podemos alterar os filtros na frequência.\n","É então interessante analisar como podemos ter o melhor resultado dos labels individualmente para cada dataset, e salvar o mesmo como csv para usarmos no modelo supervisionado posteriormente.\n","Este ajuste passa por:\n","\n","- **Filtros nas Features:** Entender os parâmetros ótimos para os filtros das Features (mediana e média móvel), além de analisar se é interessante ou não ter o elevado ao quadrado.\n","\n","- **Filtros no Cluster:** Podemos rodar um filtro no próprio cluster, para evitar falsos positivos ou negativos, para este caso usamos o mediana e run_length_smooth, quando rodamos este no cluster podemos sim escolhermos se usamos ou não, ou alterar parâmetros do mesmo para cada dataset\n","\n","- **Escolha das Features:** Pode Acontecer que para Datasets diferentes terem resultados diferentes as combinações de features utilizadas tem que ser diferentes, importante aqui é usar todas as features quando formos criar o csv, pois será utilizado no modelo supervisionado.\n","\n","- **Alteração Manual**: Como último caso podemos alterar alguns labels de forma manual, se e somente se, este forem casos isolados e tentamos todas as alternativas acima não obtendo sucesso.\n","\n","Sendo assim, devemos ao encontrar a configuração perfeita para cada dataset, salva-lo imediatamente, e documentar os parâmetros usados para deixar o resultado ótimo. Como iremos juntar depois o dataset das features cru, não tem problema utilizar estes parâmetros diferentes, depois no modelo supervisionado analisamos.\n","\n","Devemos então salvar as features **BRUTAS**, sem processamento."]},{"cell_type":"markdown","metadata":{"id":"K4GycjPYmQeH"},"source":["# Parametros Ótimos por Dataset:\n","\n","Nesse apenas setamos como 1 o dataset de contração e 0 o dataset de repouso\n","\n","Chamando a coluna de Label"]},{"cell_type":"markdown","metadata":{"id":"Xl7DN5qS-iAi"},"source":["# 🧠 Etapas de Processamento e Análise de Dados EMG\n","\n","O conjunto de dados EMG foi processado em múltiplas etapas para extração, filtragem e preparação das *features* relevantes.  \n","Essas etapas garantem que os dados estejam consistentes, livres de ruídos e adequados para análise estatística e modelagem de aprendizado de máquina.\n","\n","---\n","\n","## ⚙️ 1. Filtragem e Normalização\n","\n","Cada arquivo EMG passou por um processo de pré-tratamento das *features*, que envolveu:\n","\n","- **Suavização com média móvel** (`simple_moving_average`): reduz flutuações rápidas e melhora a estabilidade do sinal.\n","- **Filtro de mediana** (`median_clean`): remove picos abruptos de ruído preservando as bordas das contrações musculares.\n","- **Operação quadrática** (`value = value ** 2`): realça amplitudes maiores, destacando regiões de maior atividade elétrica.\n","\n","Após a filtragem, todas as *features* foram truncadas para o mesmo comprimento temporal e empilhadas em uma matriz com o formato:\n","\\[\n","X = [f_1, f_2, f_3, ..., f_n]\n","\\]\n","onde cada coluna representa uma *feature* e cada linha um *frame* temporal do sinal.\n","\n","Em seguida, aplicou-se a **normalização Min-Max**:\n","\\[\n","x_{norm} = \\frac{x - x_{min}}{x_{max} - x_{min}}\n","\\]\n","de forma a mapear todos os valores para o intervalo [0, 1], garantindo escala uniforme entre atributos e evitando que *features* com maiores magnitudes dominem o agrupamento.\n","\n","---\n","\n","## 🧩 2. Clusterização Não Supervisionada\n","\n","Com as *features* filtradas e normalizadas, aplicaram-se dois métodos distintos de aprendizado não supervisionado para identificar padrões de ativação muscular:\n","\n","### 🟢 K-Means\n","- Número de clusters: **2**\n","- Agrupa os dados com base na distância euclidiana.\n","- Útil para distinguir entre estados, como “músculo contraído” e “músculo relaxado”.\n","\n","### 🔵 Gaussian Mixture Model (GMM)\n","- Número de componentes: **2**\n","- Modelo probabilístico que permite clusters com formatos não necessariamente esféricos.\n","- Usa o método `predict()` para estimar a probabilidade de cada amostra pertencer a um cluster.\n","\n","Os rótulos de cluster obtidos foram adicionados às matrizes de *features* sob as colunas:\n","- `Clusters_Kmeans`\n","- `Clusters_GMM`\n","\n","---\n","\n","## 🧮 3. Construção do Dataset Final\n","\n","Após a clusterização, os conjuntos correspondentes a diferentes gravações EMG foram unificados.  \n","O dataset resultante foi estruturado da seguinte forma:\n","\n","\\[\n","[X_{features} \\;|\\; Cluster_{KMeans} \\;|\\; Cluster_{GMM}]\n","\\]\n","\n","Esse formato facilita a utilização posterior em tarefas supervisionadas de classificação.\n","\n","---\n","\n","## 💾 4. Exportação do Dataset\n","\n","O dataset final, contendo todas as *features* filtradas e normalizadas junto aos rótulos de clusterização, foi exportado para o arquivo:\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6CaNlJga-iQK"},"outputs":[],"source":[]}],"metadata":{"colab":{"toc_visible":true,"provenance":[],"authorship_tag":"ABX9TyPfYEc5DvusP17aztnMevJ4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}